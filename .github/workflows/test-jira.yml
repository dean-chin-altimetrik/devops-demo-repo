name: test-jira

on:
  workflow_dispatch:
    inputs:
      issue_key:
        description: "Release Scope Jira issue key"
        required: true
        type: string

permissions:
  contents: read
  # pull-requests: write   # <-- uncomment if you enable the optional PR comment step

jobs:
  check-jira:
    runs-on: ubuntu-latest
    env:
      JIRA_BASE_URL: ${{ secrets.JIRA_BASE_URL }}
      JIRA_EMAIL: ${{ secrets.JIRA_EMAIL }}
      JIRA_API_TOKEN: ${{ secrets.JIRA_API_TOKEN }}
      ISSUE_KEY: ${{ inputs.issue_key }}

    steps:
      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq
          python3 -m pip install --upgrade pip
          # libs for HTML/ADF table parsing & CSV render
          python3 -m pip install beautifulsoup4 lxml pandas

      - name: Fetch issue (type + description)
        id: fetch
        shell: bash
        run: |
          set -euo pipefail

          if [[ -z "${JIRA_BASE_URL}" || -z "${JIRA_EMAIL}" || -z "${JIRA_API_TOKEN}" ]]; then
            echo "One or more Jira secrets are missing (JIRA_BASE_URL, JIRA_EMAIL, JIRA_API_TOKEN)." >&2
            exit 2
          fi

          URL="${JIRA_BASE_URL}/rest/api/3/issue/${ISSUE_KEY}?fields=issuetype,description&expand=renderedFields"

          HTTP_STATUS=$(curl -sS -w "%{http_code}" -o /tmp/resp.json \
            -u "${JIRA_EMAIL}:${JIRA_API_TOKEN}" \
            -H "Accept: application/json" \
            "$URL")

          if [[ "$HTTP_STATUS" != "200" ]]; then
            echo "Failed to fetch issue ${ISSUE_KEY}. HTTP ${HTTP_STATUS}" >&2
            echo "Response:" >&2
            cat /tmp/resp.json >&2 || true
            exit 3
          fi

          ISSUE_TYPE=$(jq -r '.fields.issuetype.name // empty' /tmp/resp.json)
          DESC_HTML=$(jq -r '.renderedFields.description // empty' /tmp/resp.json)
          DESC_ADF=$(jq -c '.fields.description // empty' /tmp/resp.json)

          # Fallback to best-effort plain text if no rendered HTML is available
          if [[ -z "$DESC_HTML" || "$DESC_HTML" == "null" ]]; then
            DESC_TEXT=$(jq -r '
              def walkblocks($n):
                if type=="array" then map(walkblocks($n)) | join("\n")
                elif type=="object" and .type? then
                  if .type=="text" then .text // ""
                  elif .type=="paragraph" or .type=="heading" or .type=="bulletList" or .type=="orderedList"
                    then (.content // []) | map(walkblocks(.)) | join("\n")
                  elif .type=="listItem"
                    then (.content // []) | map(walkblocks(.)) | join("")
                  else (.content // []) | map(walkblocks(.)) | join("")
                  end
                else ""
                end;
              walkblocks(.)
            ' <<< "${DESC_ADF:-null}" | sed '/^[[:space:]]*$/d')
          else
            # Strip basic HTML to text
            DESC_TEXT=$(printf "%s" "$DESC_HTML" \
              | sed -E 's/<br[[:space:]]*\/?>/\n/g; s/<\/p>/\n\n/g; s/<\/li>/\n/g; s/<\/h[1-6]>/\n\n/g' \
              | sed -E 's/<[^>]+>//g' \
              | sed -E 's/[[:space:]]+$//')
          fi

          IS_REL_SCOPE=false
          if [[ "$ISSUE_TYPE" == "REL-SCOPE" ]]; then
            IS_REL_SCOPE=true
          fi

          {
            echo "issue_type=${ISSUE_TYPE}"
            echo "is_rel_scope=${IS_REL_SCOPE}"
            echo "description<<EOF"
            printf "%s\n" "$DESC_TEXT"
            echo "EOF"
          } >> "$GITHUB_OUTPUT"

      - name: Parse description tables (HTML -> Markdown + CSV)
        id: parse_html_tables
        env:
          RAW_JSON_PATH: /tmp/resp.json
        run: |
          set -euo pipefail
          python3 - << 'PY'
import json, os, re, io, sys
from bs4 import BeautifulSoup
import pandas as pd

raw_path = os.environ["RAW_JSON_PATH"]
with open(raw_path, "r", encoding="utf-8") as f:
    data = json.load(f)

desc_html = data.get("renderedFields", {}).get("description") or ""
desc_html = desc_html if isinstance(desc_html, str) else ""

tables_found = 0
summary_blocks = []

text_only = ""
if desc_html:
    soup = BeautifulSoup(desc_html, "lxml")
    # Gather HTML tables
    for idx, table in enumerate(soup.find_all("table"), start=1):
        try:
            dfs = pd.read_html(str(table))
        except Exception:
            dfs = []
        if not dfs:
            continue
        df = dfs[0]
        tables_found += 1

        csv_path = f"/tmp/jira_description_table_{idx}.csv"
        df.to_csv(csv_path, index=False)
        md = df.to_markdown(index=False)
        summary_blocks.append(f"### Table {idx}\n\n{md}\n")

    # Produce a plain-text copy of non-table content for context
    for br in soup.find_all(["br"]):
        br.replace_with("\n")
    for p in soup.find_all(["p","h1","h2","h3","h4","h5","h6","li"]):
        if p.name == "li":
            p.insert_before("- ")
        p.append("\n")
    text_only = re.sub("<[^>]+>", "", soup.decode()).strip()

# Emit outputs
with open(os.environ["GITHUB_OUTPUT"], "a", encoding="utf-8") as gout:
    gout.write(f"tables_found_html={tables_found}\n")

# Write a Job Summary section (HTML branch). ADF fallback will append more if used.
summary = io.StringIO()
summary.write("## Jira Description\n\n")
if tables_found:
    summary.write(f"> Detected **{tables_found}** table(s) in the Jira description (HTML).\n\n")
    summary.write("\n".join(summary_blocks))
else:
    if text_only:
        summary.write("No tables detected in HTML. Description (text):\n\n```\n")
        summary.write(text_only[:8000])
        if len(text_only) > 8000:
            summary.write("\n... (truncated) ...\n")
        summary.write("\n```\n")
    else:
        summary.write("_No description found in HTML._\n")

with open(os.environ["GITHUB_STEP_SUMMARY"], "a", encoding="utf-8") as f:
    f.write(summary.getvalue())
PY

      - name: Parse ADF tables (fallback if no HTML tables)
        id: parse_adf_tables
        if: ${{ steps.parse_html_tables.outputs.tables_found_html == '0' }}
        run: |
          python3 - << 'PY'
import json, os, io, csv

raw_path = "/tmp/resp.json"
with open(raw_path, "r", encoding="utf-8") as f:
    data = json.load(f)

adf = data.get("fields", {}).get("description")
if not isinstance(adf, dict):
    # No ADF available
    with open(os.environ["GITHUB_OUTPUT"], "a") as gout:
        gout.write("tables_found_adf=0\n")
    raise SystemExit(0)

def extract_text(node):
    t = node.get("type")
    if t == "text":
        return node.get("text","")
    # Recurse contents
    return "".join(extract_text(c) for c in (node.get("content") or []))

tables = []
for node in (adf.get("content") or []):
    if node.get("type") == "table":
        rows = []
        for row in (node.get("content") or []):   # tableRow
            cells = []
            for cell in (row.get("content") or []):  # tableCell/tableHeader
                cell_text = "".join(extract_text(piece) for piece in (cell.get("content") or []))
                cells.append(cell_text.strip())
            rows.append(cells)
        tables.append(rows)

count = 0
summary = io.StringIO()
if tables:
    summary.write("## Jira Description (ADF tables)\n\n")
for i, rows in enumerate(tables, start=1):
    width = max((len(r) for r in rows), default=0)
    rows = [r + [""]*(width-len(r)) for r in rows]

    # CSV artifact
    csv_path = f"/tmp/jira_adf_table_{i}.csv"
    with open(csv_path, "w", encoding="utf-8", newline="") as f:
        csv.writer(f).writerows(rows)

    # Markdown table
    if rows:
        header = rows[0]
        summary.write(f"### Table {i}\n\n")
        summary.write("| " + " | ".join(h or "" for h in header) + " |\n")
        summary.write("| " + " | ".join("---" for _ in header) + " |\n")
        for r in rows[1:]:
            summary.write("| " + " | ".join(c or "" for c in r) + " |\n")
        summary.write("\n")
        count += 1

with open(os.environ["GITHUB_STEP_SUMMARY"], "a", encoding="utf-8") as f:
    f.write(summary.getvalue())

with open(os.environ["GITHUB_OUTPUT"], "a") as gout:
    gout.write(f"tables_found_adf={count}\n")
PY

      - name: Upload table CSVs (if any)
        uses: actions/upload-artifact@v4
        if: |
          steps.parse_html_tables.outputs.tables_found_html != '0' || steps.parse_adf_tables.outputs.tables_found_adf != '0'
        with:
          name: jira-description-tables
          path: |
            /tmp/jira_description_table_*.csv
            /tmp/jira_adf_table_*.csv
          if-no-files-found: ignore

      - name: Log results
        run: |
          echo "Issue Type: ${{ steps.fetch.outputs.issue_type }}"
          echo "Is REL-SCOPE: ${{ steps.fetch.outputs.is_rel_scope }}"
          echo "----- Description (plain text) -----"
          printf "%s\n" "${{ steps.fetch.outputs.description }}"

      # Optional guardrail: fail if the issue type is not REL-SCOPE
      - name: Enforce REL-SCOPE (optional)
        if: ${{ steps.fetch.outputs.is_rel_scope != 'true' }}
        run: |
          echo "Issue type is not REL-SCOPE; failing as per policy." >&2
          exit 1

      # OPTIONAL: comment a short note on PRs (enable triggers/permissions above)
      # - name: Comment tables on PR
      #   if: ${{ github.event_name == 'pull_request' && (steps.parse_html_tables.outputs.tables_found_html != '0' || steps.parse_adf_tables.outputs.tables_found_adf != '0') }}
      #   uses: peter-evans/create-or-update-comment@v4
      #   with:
      #     issue-number: ${{ github.event.pull_request.number }}
      #     body: |
      #       **Jira Description Tables**
      #       Detected tables in Jira description. See the workflow **Job Summary** for nicely formatted tables and download the **jira-description-tables** artifact for CSVs.